# -*- coding: utf-8 -*-
"""The project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d_4if4DgiXLR9WOGJ-Zkc1ZqakR36JAD
"""

import pandas as pd

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.metrics
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier

!pip install kaggle

!kaggle datasets download iremnurtokuroglu/credit-score-classification-cleaned-dataset

!unzip credit-score-classification-cleaned-dataset.zip

df = pd.read_csv('credit_score_cleaned_train.csv')

df.head()

df.info()

df.shape

df.describe()

df.isnull().sum()

object_columns = df.columns[df.dtypes == 'object']
object_columns

df.dtypes

unique_names2 = df['occupation'].unique()
print(unique_names2)

unique_names3 = df['payment_behaviour'].unique()
print(unique_names3)

unique_names4 = df['type_of_loan'].unique()
print(unique_names4)

unique_loan_types = ['Auto Loan', 'Credit-Builder Loan', 'Debt Consolidation Loan', 'Home Equity Loan', 'Mortgage Loan',
                     'No Loan', 'Not Specified', 'Payday Loan', 'Personal Loan', 'Student Loan']

for element in unique_loan_types:
  cleaned_loan_type = element.replace(' ', '_').replace('-', '_').lower()
  df[cleaned_loan_type] = df['type_of_loan'].apply(lambda x: x.count(element))

df.columns

df.dtypes

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['occupation_encoded'] = le.fit_transform(df['occupation'])
le1 = LabelEncoder()
df['credit_mix_encoded'] = le1.fit_transform(df['credit_mix'])
le2 = LabelEncoder()
df['payment_behaviour_encoded'] = le2.fit_transform(df['payment_behaviour'])

df.drop(columns=['id','customer_id', 'month','name','ssn'], axis=1, inplace=True)

df.drop(columns=['occupation', 'credit_mix', 'payment_of_min_amount', 'payment_behaviour', 'type_of_loan'], axis=1, inplace=True)

df.info()

"""OUTLIERS DETECTION"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.xticks(rotation=90)
plt.title('Boxplots of the data')
plt.show()

sns.boxplot(x=df['annual_income'])
plt.title('Boxplot for Outlier Detection')
plt.show()

sns.boxplot(x=df['monthly_inhand_salary'])
plt.title('Boxplot for Outlier Detection')
plt.show()

sns.boxplot(x=df['total_emi_per_month'])
plt.title('Boxplot for Outlier Detection')
plt.show()

sns.boxplot(x=df['delay_from_due_date'])
plt.title('Boxplot for Outlier Detection')
plt.show()

sns.boxplot(x=df['changed_credit_limit'])
plt.title('Boxplot for Outlier Detection')
plt.show()

sns.boxplot(x=df['num_credit_inquiries'])
plt.title('Boxplot for Outlier Detection')
plt.show()

sns.boxplot(x=df['amount_invested_monthly'])
plt.title('Boxplot for Outlier Detection')
plt.show()

sns.boxplot(x=df['monthly_balance'])
plt.title('Boxplot for Outlier Detection')
plt.show()

import numpy as np
from scipy.stats import zscore
z_scores = np.abs(zscore(df))

df['z_score_annual_income'] = zscore(df['annual_income'])
df['z_score_monthly_inhand_salary'] = zscore(df['monthly_inhand_salary'])
df['z_score_total_emi_per_month'] = zscore(df['total_emi_per_month'])
df['z_score_delay_from_due_date'] = zscore(df['delay_from_due_date'])
df['z_score_changed_credit_limit'] = zscore(df['changed_credit_limit'])
df['z_score_num_credit_inquiries'] = zscore(df['num_credit_inquiries'])
df['z_score_amount_invested_monthly'] = zscore(df['amount_invested_monthly'])
df['z_score_monthly_balance'] = zscore(df['monthly_balance'])
df['z_score_credit_utilization_ratio'] = zscore(df['credit_utilization_ratio'])
df['z_score_outstanding_debt'] = zscore(df['outstanding_debt'])
df1 = df[df['z_score_annual_income'].abs() <= 3].drop(columns='z_score_annual_income')
df1 = df1[df1['z_score_monthly_inhand_salary'].abs() <= 3].drop(columns='z_score_monthly_inhand_salary')
df1 = df1[df1['z_score_total_emi_per_month'].abs() <= 3].drop(columns='z_score_total_emi_per_month')
df1 = df1[df1['z_score_delay_from_due_date'].abs() <= 3].drop(columns='z_score_delay_from_due_date')
df1 = df1[df1['z_score_changed_credit_limit'].abs() <= 3].drop(columns='z_score_changed_credit_limit')
df1 = df1[df1['z_score_num_credit_inquiries'].abs() <= 3].drop(columns='z_score_num_credit_inquiries')
df1 = df1[df1['z_score_amount_invested_monthly'].abs() <= 3].drop(columns='z_score_amount_invested_monthly')
df1 = df1[df1['z_score_monthly_balance'].abs() <= 3].drop(columns='z_score_monthly_balance')
df1 = df1[df1['z_score_credit_utilization_ratio'].abs() <= 3].drop(columns='z_score_credit_utilization_ratio')
df1 = df1[df1['z_score_outstanding_debt'].abs() <= 3].drop(columns='z_score_outstanding_debt')

plt.figure(figsize=(10, 6))
sns.boxplot(data=df1)
plt.xticks(rotation=90)
plt.title('Boxplots of the data')
plt.show()

df1.describe()

df1['credit_score'].value_counts()

from sklearn.preprocessing import StandardScaler

exclude_cols = ['age', 'credit_score', 'auto_loan', 'credit_builder_loan',
       'debt_consolidation_loan', 'home_equity_loan', 'mortgage_loan',
       'no_loan', 'not_specified', 'payday_loan', 'personal_loan',
       'student_loan','occupation_encoded','credit_mix_encoded', 'payment_behaviour_encoded']

numeric_cols = df1.select_dtypes(include=['float64', 'int64']).columns
cols_to_scale = [col for col in numeric_cols if col not in exclude_cols]

scaler = StandardScaler()
df1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])

df1.columns

import matplotlib.pyplot as plt
fig, axes = plt.subplots(17, 2, figsize=(20, 25))

# List of columns to plot
columns = ['age', 'annual_income', 'monthly_inhand_salary', 'total_emi_per_month',
       'num_bank_accounts', 'num_credit_card', 'interest_rate', 'num_of_loan',
       'delay_from_due_date', 'num_of_delayed_payment', 'changed_credit_limit',
       'num_credit_inquiries', 'outstanding_debt', 'credit_utilization_ratio',
       'credit_history_age', 'amount_invested_monthly', 'monthly_balance',
       'credit_score', 'auto_loan', 'credit_builder_loan',
       'debt_consolidation_loan', 'home_equity_loan', 'mortgage_loan',
       'no_loan', 'not_specified', 'payday_loan', 'personal_loan',
       'student_loan', 'occupation_encoded', 'credit_mix_encoded',
       'payment_behaviour_encoded']


# Loop through columns and plot histograms
for i, col in enumerate(columns):
    # Determine row and column index for each plot
    row = i // 2
    col_idx = i % 2

    # Plot histogram for the column
    axes[row, col_idx].hist(df1[col], bins=17, color='blue', alpha=0.7)
    axes[row, col_idx].set_title(f'Histogram of {col}')
    axes[row, col_idx].set_xlabel('Value')
    axes[row, col_idx].set_ylabel('Frequency')

# Adjust layout for better spacing
plt.tight_layout()

# Show the plot
plt.show()

X = df1.drop(['credit_score'], axis=1)

y = df1['credit_score']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 40)

!pip install imbalanced-learn

from imblearn.over_sampling import SMOTE
from collections import Counter

smote = SMOTE(sampling_strategy='auto', random_state=42)  # 'auto' means balance all classes
X_res, y_res = smote.fit_resample(X_train, y_train)

print("After SMOTE:", Counter(y_res))

X_train.shape, X_test.shape

X_train.dtypes

X.columns

X_train.head()

X_test.head()

"""CLASSIFICATION USING DIFFERENT MODELS

Decision Tree Classifier
"""

from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 15)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

accuracy_score(y_test, y_pred)

"""Random Forest Classifier"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'criterion': ['gini'],
    'max_depth': [22, 24, 26,29],
    'min_samples_split': [10,20,30],
    'n_estimators' : [20,50,70,100]
}

grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=15), param_grid=param_grid, scoring = 'recall', cv=10)
grid_search.fit(X_train, y_train)

print("Best parameters found: ", grid_search.best_params_)
print("Best score achieved: ", grid_search.best_score_)

rfc_20 = RandomForestClassifier(
    n_estimators=20,
    criterion="gini",
    max_depth=22,
    min_samples_split=10)
rfc_20.fit(X_train, y_train)
y_pred_20 = rfc_20.predict(X_test)

print('Model accuracy score with 20 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_20)))

from sklearn.model_selection import cross_validate
cv_results = cross_validate(rfc_20, X, y, cv=11)
cv_results['test_score']

cv_results['test_score'].mean()

# Print the Confusion Matrix

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

print('Confusion matrix\n\n', cm)

sns.heatmap(data=cm,annot=True)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

"""Classification using neural network model"""

import tensorflow as tf

# Build the Neural Network model
model = tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(8, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')  # 3 output classes for credit scoring
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
essay = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))

# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_accuracy:.4f}")

# Make predictions
y_pred_prob = model.predict(X_test)
y_pred = np.argmax(y_pred_prob, axis=1)

# Evaluate prediction accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of predictions: {accuracy:.4f}")

"""So, after comparing the accuracy of predictions between Random Forest, Decision Trees and Neural Network models, we see that the higher accuracy is when we use Random Forest. That is why we will use it in our application."""

import joblib

joblib.dump(rfc_20, 'random_forest_model.joblib')

loaded_model = joblib.load('random_forest_model.joblib')

predict = loaded_model.predict(X_test)

predict

y_test

P=pd.DataFrame(predict)
P.value_counts()

P= pd.DataFrame(predict)
P.value_counts()

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

print('Confusion matrix\n\n', cm)

import pickle

with open ('le.pkl', 'wb') as file:
  pickle.dump(le, file)

with open ('le1.pkl', 'wb') as file:
  pickle.dump(le1, file)

with open ('le2.pkl', 'wb') as file:
  pickle.dump(le2, file)

joblib.dump(scaler, 'scaler.pkl')

scaler = joblib.load('scaler.pkl')

df1.columns

df1.dtypes